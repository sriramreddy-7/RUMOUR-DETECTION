{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Cb7ZsUHlinIzEyH0ci3YH1pl7YiDkH3u",
      "authorship_tag": "ABX9TyO0fLPOKz2QEgJpOg4BbiCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriramreddy-7/RUMOUR-DETECTION/blob/main/RD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AmxNyUfRN0jJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fe69b6-1e14-419f-ff5d-7ef6d24d190a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "metadata": {
        "id": "B0oKqG5uhY4B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data(json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "9OloJADViNiE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_path=\"/content/drive/MyDrive/[07] Datasets/ML (1)/pheme/data.json\""
      ],
      "metadata": {
        "id": "r16tzlhFhtSx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pheme_df = load_json_data(json_path)"
      ],
      "metadata": {
        "id": "JQmiFGMFiQxR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pheme_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Efi3dmkBJL",
        "outputId": "f19b2b1e-df12-409b-d03e-bcb4fd31cb87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'text', 'image', 'label', 'nodes', 'edges'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_column = 'image'"
      ],
      "metadata": {
        "id": "GNMcxGE0kFk4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_folder = '/content/drive/MyDrive/[07] Datasets/ML (1)/pheme/images'\n",
        "existing_images = set(os.listdir(images_folder))"
      ],
      "metadata": {
        "id": "-t5vZI95iSPW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pheme_df['image_exists'] = pheme_df[image_column].apply(lambda x: x in existing_images)\n",
        "filtered_pheme_df = pheme_df[pheme_df['image_exists']]"
      ],
      "metadata": {
        "id": "fcF9kCVgiUil"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder_path, img_height, img_width, filenames):\n",
        "    images = []\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = load_img(img_path, target_size=(img_height, img_width))\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)"
      ],
      "metadata": {
        "id": "1V2nPn8oiWX2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "image_filenames = filtered_pheme_df[image_column].tolist()"
      ],
      "metadata": {
        "id": "m8tsDBtfjEhu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = load_images_from_folder(images_folder, IMG_HEIGHT, IMG_WIDTH, image_filenames)\n",
        "\n",
        "# Update DataFrame to only include rows with loaded images\n",
        "filtered_pheme_df = filtered_pheme_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k5XVz1a-lUso"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NB_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(filtered_pheme_df['text'])"
      ],
      "metadata": {
        "id": "MC7Rppv-iZ12"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(filtered_pheme_df['text'])\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "KBObMEQvicBk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "T1fV_4sJihd9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = filtered_pheme_df['label'].values"
      ],
      "metadata": {
        "id": "pAx9Qpn6kyO-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'text_data length: {len(text_data)}, image_data length: {len(image_data)}, labels length: {len(labels)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVij0u9rk0e6",
        "outputId": "2c9bc200-6dd1-4a3f-d5a0-856cedaae42b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_data length: 920, image_data length: 920, labels length: 920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = filtered_pheme_df['label'].astype(int).values"
      ],
      "metadata": {
        "id": "Ww51JK_1mdGS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = np.array(text_data, dtype=np.float32)\n",
        "image_data = np.array(image_data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "wRtEC0GdmgsS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Ak4j3a5-mjlx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_train, text_test, img_train, img_test, y_train, y_test = train_test_split(\n",
        "    text_data, image_data, labels, test_size=0.2, stratify=labels)"
      ],
      "metadata": {
        "id": "6JtbddkimkGg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"text_train dtype: {text_train.dtype}, img_train dtype: {img_train.dtype}, y_train dtype: {y_train.dtype}\")\n",
        "print(f\"text_test dtype: {text_test.dtype}, img_test dtype: {img_test.dtype}, y_test dtype: {y_test.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyvVHKFfk1LN",
        "outputId": "dc3b2913-121b-40d2-9bfb-169a79cd2a6f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_train dtype: float32, img_train dtype: float32, y_train dtype: int64\n",
            "text_test dtype: float32, img_test dtype: float32, y_test dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCQI067wilNx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Conv2D, MaxPooling2D, Flatten, concatenate"
      ],
      "metadata": {
        "id": "XjHDezVdiqs9"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_text = Embedding(MAX_NB_WORDS, EMBEDDING_DIM)(text_input)\n",
        "lstm_text = LSTM(128)(embedded_text)"
      ],
      "metadata": {
        "id": "mTMgJWablAhD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), dtype='float32')\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "flatten_img = Flatten()(pool2)"
      ],
      "metadata": {
        "id": "pT2T4DLnlA6x"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated = concatenate([lstm_text, flatten_img])"
      ],
      "metadata": {
        "id": "ZOaaJ2QGl8zk"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "# Compile the model\n",
        "model = Model(inputs=[text_input, image_input], outputs=output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hyktgYoxmEXt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([text_train, img_train], y_train,\n",
        "                    epochs=10, batch_size=32, validation_data=([text_test, img_test], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPlYK_AWmHi8",
        "outputId": "a1c47cc4-0c78-4213-b4dc-b2710b6f4f16"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 69s 3s/step - loss: 153.9206 - accuracy: 0.5557 - val_loss: 1.0406 - val_accuracy: 0.4511\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 63s 3s/step - loss: 0.7003 - accuracy: 0.6739 - val_loss: 0.7306 - val_accuracy: 0.6902\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 65s 3s/step - loss: 0.5788 - accuracy: 0.7582 - val_loss: 0.6884 - val_accuracy: 0.7228\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 64s 3s/step - loss: 0.4891 - accuracy: 0.7663 - val_loss: 0.6876 - val_accuracy: 0.7283\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 72s 3s/step - loss: 0.4042 - accuracy: 0.8098 - val_loss: 0.7315 - val_accuracy: 0.6685\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 64s 3s/step - loss: 0.2945 - accuracy: 0.8682 - val_loss: 0.8869 - val_accuracy: 0.6848\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 65s 3s/step - loss: 0.1964 - accuracy: 0.9198 - val_loss: 0.8890 - val_accuracy: 0.6576\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.1164 - accuracy: 0.9620 - val_loss: 1.3375 - val_accuracy: 0.6739\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 64s 3s/step - loss: 0.0545 - accuracy: 0.9891 - val_loss: 1.2040 - val_accuracy: 0.6467\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 64s 3s/step - loss: 0.0388 - accuracy: 0.9959 - val_loss: 1.0432 - val_accuracy: 0.6739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate([text_test, img_test], y_test)\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tbwlEbJnAXJ",
        "outputId": "ccf9c613-6666-44fd-b928-bd0acceb5a16"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 4s 641ms/step - loss: 1.0432 - accuracy: 0.6739\n",
            "Test accuracy: 0.6739130616188049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict([text_test, img_test]) > 0.5).astype(int)\n",
        "\n",
        "# Import classification report and accuracy score\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Print accuracy score\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zecW83QkmKHy",
        "outputId": "1c522b39-ea13-4dc7-ddc4-f67bca988c32"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 5s 697ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.86      0.78       125\n",
            "           1       0.48      0.27      0.35        59\n",
            "\n",
            "    accuracy                           0.67       184\n",
            "   macro avg       0.60      0.57      0.57       184\n",
            "weighted avg       0.64      0.67      0.64       184\n",
            "\n",
            "Accuracy Score: 0.6739130434782609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-g2cr6Hqeg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}